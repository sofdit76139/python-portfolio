{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374a8899-fcdf-4790-82a4-bfbeecc2f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cnxn = pyodbc.connect(driver = '{ODBC Driver 17 for SQL Server}', server = 'tcp:10.3.6.50', database = 'reports', trusted_connection = 'yes')\n",
    "\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "#####\n",
    "#AX items\n",
    "#####\n",
    "\n",
    "query = '''\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM SD_items_by_vendor_UPC2\n",
    "\n",
    "'''\n",
    "\n",
    "dfLHA = pd.read_sql(query, cnxn)\n",
    "\n",
    "\n",
    "#####\n",
    "#item groups\n",
    "#####\n",
    "\n",
    "query = '''\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM SD_Item_Groups\n",
    "\n",
    "'''\n",
    "\n",
    "dfItemGroups = pd.read_sql(query, cnxn)\n",
    "\n",
    "#####\n",
    "#categories\n",
    "#####\n",
    "\n",
    "query = '''\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM SD_AX_Item_Categories\n",
    "\n",
    "'''\n",
    "\n",
    "dfCategories = pd.read_sql(query, cnxn)\n",
    "\n",
    "\n",
    "#####\n",
    "#sections\n",
    "#####\n",
    "\n",
    "query = '''\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM SD_store_sections\n",
    "\n",
    "'''\n",
    "\n",
    "dfSections = pd.read_sql(query, cnxn)\n",
    "\n",
    "\n",
    "#####\n",
    "#locations\n",
    "#####\n",
    "\n",
    "query = '''\n",
    "\n",
    "SELECT *\n",
    "\n",
    "FROM SD_inventory_locations\n",
    "\n",
    "WHERE INVENTLOCATIONID NOT LIKE 'DAL%'\n",
    "\n",
    "'''\n",
    "\n",
    "dfLocations = pd.read_sql(query, cnxn)\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c5f94-8c0a-4e6f-bcbf-842dd36db099",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLHA.drop(dfLHA.columns[[2,3,6,7,8,9,10,13,14,15]], axis = 1, inplace = True)\n",
    "dfCategories.drop(dfCategories.columns[[1]], axis = 1, inplace = True)\n",
    "\n",
    "dfItemGroups['ITEMGROUPID'] = dfItemGroups['ITEMGROUPID'].str.upper()\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [dfLHA, dfItemGroups, dfCategories]\n",
    "\n",
    "df_merged = reduce(lambda left,right: pd.merge(left,right,on=['ITEMID'], how='left'), data_frames).fillna('null')\n",
    "\n",
    "# df_merged['InventoryAvailable'] = df_merged['InventoryAvailable'].fillna(0)\n",
    "\n",
    "df_merged['InventoryAvailable'] = df_merged['InventoryAvailable'].replace({'null':'0'})\n",
    "\n",
    "df_merged['InventoryAvailable'] = pd.to_numeric(df_merged['InventoryAvailable'], downcast='integer')\n",
    "\n",
    "cond1 = df_merged['InventoryAvailable'] > 0\n",
    "cond2 = df_merged['ITEMGROUPID'] != 'MAP'\n",
    "cond3 = df_merged['SubCategory'] != 'Cards'\n",
    "cond4 = df_merged['SubSubCategory'] != 'Apparel/Accessories'\n",
    "cond5 = df_merged['SubSubCategory'] != 'Soda'\n",
    "cond6 = df_merged['SubSubCategory'] != 'Seasonal Candy'\n",
    "cond7 = df_merged['SubSubCategory'] != 'Holiday'\n",
    "\n",
    "df_merged = df_merged[cond1]\n",
    "\n",
    "df_merged = df_merged[cond2]\n",
    "\n",
    "df_merged = df_merged[cond3]\n",
    "\n",
    "df_merged = df_merged[cond4 & cond5 & cond6 & cond7]\n",
    "\n",
    "df_merged.drop_duplicates(subset = ['ITEMID', 'BarCode'], keep = False, inplace = True)\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [df_merged, dfSections]\n",
    "\n",
    "df_merged_final = reduce(lambda left,right: pd.merge(left,right,on=['ITEMID'], how='outer'), data_frames).fillna('null')\n",
    "\n",
    "df_merged_final = (df_merged_final[(df_merged_final['SECTIONID'] == 'null')])\n",
    "\n",
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [df_merged_final, dfLocations]\n",
    "\n",
    "df_merged_final_loc = reduce(lambda left,right: pd.merge(left,right,on=['ITEMID'], how='left'), data_frames).fillna('null')\n",
    "\n",
    "df_merged_final_loc.drop_duplicates(subset = ['ITEMID', 'WMSLOCATIONID'], keep = False, inplace = True)\n",
    "\n",
    "df_merged_final_loc.drop(df_merged_final_loc.columns[[5,8,9,10,11,12,14]], axis = 1, inplace = True)\n",
    "\n",
    "df_merged_final_loc.rename(columns={'NAMEALIAS_x': 'NAMEALIAS', 'ITEMGROUPID': 'DEPT', 'WMSLOCATIONID': 'Location'}, inplace=True)\n",
    "\n",
    "df_merged_final_loc.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_merged_final_loc['SubCategory'] = df_merged_final_loc['SubCategory'].replace({'null':''})\n",
    "\n",
    "myPath = 'C:/Users/USER/OneDrive - COMPANY/Merchandising Documents/AX Imports/Store/Sections/Output/'\n",
    "\n",
    "myDate = pd.datetime.today().strftime('%Y_%m_%d %H_%M')\n",
    "\n",
    "df_merged_final_loc.to_excel(myPath + myDate + ' ItemsNoSections.xlsx', index=False, header=True)\n",
    "\n",
    "df_merged_final_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3da70654-3b64-4fb9-9070-bc23c5a5c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ITEMID\n",
      "1 - NAMEALIAS_x\n",
      "2 - ExternalID\n",
      "3 - BarCode\n",
      "4 - Discontinued\n",
      "5 - InventoryAvailable\n",
      "6 - ITEMGROUPID\n",
      "7 - SubCategory\n",
      "8 - SubSubCategory\n",
      "9 - SubSubSubCategory\n",
      "10 - NAMEALIAS_y\n",
      "11 - STOREID\n",
      "12 - SECTIONID\n",
      "13 - PhysicalInventory\n",
      "14 - INVENTLOCATIONID\n",
      "15 - WMSLOCATIONID\n"
     ]
    }
   ],
   "source": [
    "myColumnCount = len(df_merged_final_loc.columns)\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < myColumnCount:\n",
    "    col = df_merged_final_loc.columns[i]\n",
    "    # Get column index position of column\n",
    "    col_index = list(df_merged_final_loc.columns).index(df_merged_final_loc.columns[i])\n",
    "    print(str(col_index) + ' - ' + col)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e231b-d416-4ddf-b30e-04dbc70f10f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
